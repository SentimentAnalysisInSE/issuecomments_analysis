Lets fix this post wss4j-1.5.3
Reassign to fix in future release.
Sorry clicked the wrong button. Its intended for inclusion.
well if the user uploaded a file in the first FileUploadField then it should be handled by the first nested Form and if he uploaded a file in the second then it should be handled by the second and if both ... then both !  If only outer Form process all the submit then I understand that it can be difficult to implement what I expect are nested Form informed of the submition or not ? In fact FileUploadException is raised only for size limit exceeded can't we handle this thru an IFormValidator instead of a hardcoded check ?
A Quickstart for the bug as Eclipse/Maven Project. Sorry for the delay.
I didn't have time to work on this yet ...
"Sorry forgot to mention this. Try to switch the tabs a second time. The first click on ""Tab B"" will correctly render ""Content B"". But switching back to ""Tab A"" and then again back to ""Tab B"" fails to render ""Content B""."
Thank you!
Fix applied thanks.
Ah great thanks!     
thanks Attila. I fixed the test/header already
I see no gain to make it singleton (Scala object) too. No need to change it without reason.
Sorry I narrowed down the issue to Chrome's over-zealous caching. I was able to reproduce the problem on two separate computers in a simple project where I had upgraded from Wicket 1.4.0 to 1.4.15. But due to testing before and after Chrome had cached the buggy version of wicket-ajax.js from 1.4.0 and did not detect that it changed with the update. Clearing the browser cache resolved the issue.  Sorry about the bogus bug report.
this was released in 1.4.9 but is now being reverted in 1.4.10 due to overwhelming community feedback
thanks
model objects were not serializable
Quickstart to demonstrate that I can't reproduce this.
Sounds like a good idea but better to only fix in 1.5 to keep 1.4 more 1.3-compatible.
Builds fine for me and the code looks good. Great work! I did not run the integration tests.   [~abayer] what do you think?
This looks good to me. +1 pending beta-8.
You are right its the wrong one (an older attempt).
I agree. I'm planning to look into WHIRR-370 later this month but I can't provide a timeline for it. 
Ok. I will do that. Adrian thanks for taking a look at this. :) 
Forgot to grant license
+1 Looks good to me.
This patch adds some getting started documentation and also a new page about configuration. I've removed the individual pages for services in the absence of something to write there but we can add back as needed. I've also commented out some broken links that won't be live until we do a release.  I think we could make this live now. Thoughts?  BTW before applying the patch run:  svn mv site/src/site/confluence/getting-started.confluence site/src/site/confluence/quick-start-guide.confluence
Attached image showing blip padding in the Google Wave client.
Sorry forgot to mention it in issue description. I use commons-net-2.0.jar i.e. version 2.0.  It's because Scott Bjerstedt wrote in VFS-264 that for his patch to work we need to use commons-net 2.0.
"It took me a while to figure out where the problem is coming from sorry.  So your way is not a bad way of doing it though let me suggest an alternative...  In AbstractFileObject match the constructor's ""fs.fileObjectHanded(this)"
Hmm.  Breaking #if($query.foo) compatibility isn't ok if we can't find a reasonable way to keep that and the sub then i'll ditch the sub.   But i much prefer $query.foo.bar over $query.get('foo.bar') so i'm not going to give that up quickly.  The type conversion suffixes are more than just nice since the main point of the ValueParser is to parse values.  If you don't care about type conversion then you may as well just put the source map into the context.  Anyway i'm going to see if i can make both work somehow.  If i can't then expect me to resurrect the sub in a later version where complete backwards compatibility isn't necessary.
Nice!  Thanks for adding nice debug logging too :-) 
reopened for fixVersion
reopened for fixVersion
Oops my bad sorry. I indeed did not 'svn add' the new classes since I don't have write access to the repository anyway. But this way 'svn diff' goes wrong of course. I will submit a new patch on Monday when I'm back at my working machine. I'm really sorry for the incovencience!
Fixed typo in title
The fix causes test to fail in other circumstances.  Apparently File.delete() can't be relied upon to actually delete the file.
Thanks for the patch Greg. Applied at r1153789
Thanks for the patch applied to 1.x and 1.5.1
Committed to 1.3.3 at revision: 705591   
Committed to 1.3.1 branch at revision: 685854   
fix also applied to the Native SDO repo on revision 671633
Fixed in SCA Java 1.2 rc4.
The diffs look good to me but it sounds like this only solves part of hte problems so we should probably file another bug to get the mgmt GUI 100% functional (for 2.1 maybe?).
Patch Commited closing bug
1.2.x patch attached
"Have a look at current svn head i have changed the styling stuff of the component with this approach it should work now. Just specify the ""style"" attribute and give it a width value.   I also have had a look at how we can influence the default Dojo styling stuff and have updated the wiki on this:  http://wiki.apache.org/myfaces/InputSuggestAjax  Can you test it if it works for you?    "
Thanks again to Claudio Tasso
patch by Dennis Byrne. Thanks a lot!
Hi  I was going to join in on reporting this problem. I had recently downloaded a build from 10/17/2005 in order to fix a problem I was experiencing with jscookmenu. It was not until today that I ran a test in IE and found inputcalendar didn't work. I had the same JavaScript error: dateFormatSymbols. The calendar worked fine in Firefox.  Today I downloaded MyFaces 1.1.1RC3 and can confirm that this problem no longer seems to exist for me.   Cheers Kevin 
patches applied revision 434193
Good advice this works...
Patch applied. Thanks Matt!
Thanks. Yes when that fragment is part of an RTF file it provokes the exception so if you could put it into a valid RTF file it should throw the exception.
Setting to midnight UTC after parsing sounds fine to me.  yyyy-mm-dd looks good too.
bq. {{ catch (InterruptedException ignore) { Thread.currentThread().interrupt()
one additional example: http://www.who.int/entity/tb/publications/global_report/gtbr12_execsummary_ar.pdf
Fixed in revision 903352. The change should get published in a few hours.
Keith -  This is done.  Thanks
thanks Randy!  committed 
Thanks Avi!
Excellent thanks a lot!
Committed thanks Dave
Hi [~wikimore] [~michaelstockton] or any other Ruby user: I'd really like to commit that but I need someone of you to review and confirm before. So if you want this being part of the next release .... thank you!  
I just committed this patch. Thanks Richard!
patch that replaces the numeric constant value with the symbolic name of the enumerated constant
Any feedback on the updated patch?  I'm guessing it won't cleanly apply to trunk anymore since it's been two weeks but if the general idea looks correct I can update it to apply cleanly to the current trunk.
I'm still not in love with the sarcasm or excessive negativity.  I'll just point a few things out.  1/ I didn't veto anything and this has nothing to do with C++.  I think it is a bad idea for us to generate code in a way that causes semantics to silently change when a new optional field is added.  This in dangerous in the long term.  2/ I have no problem reverting this change.  3/ Restoring the old constructor and marking in deprecated is probably a good idea.
"> David Reiss writes: > As I recall Jonathan was the only person who really seemed to > care about this issue and he wasn't satisfied with my > suggestion so I put it aside. Chad also requested some changes > to my diff for the JSON protocol. I'll try to reevaluate the > status some time soon but I am away from a computer today.  Jonathan - are you still in the loop on this one?  What do you think?  Given the fundamental differences in what a ""string"" is across different languages there's unlikely to be a clean solution that suits everyone. Having a backwards-compatible compromise that works is much better than having nothing though. "
Sorry about that.
Any reason not to commit this patch? It's been hanging around a long time.
Committed revision 700277. 
David lgtm  Bryan I believe assignee should be Erik as the author of initial version of patch but I can't find him in drop box.
Hi   I have re-based the patch based on the latest master branch.  Please review and let me know if any changes are required.
Committed. Thanks Hitesh
"[~mikelid] Please take a look at the patch when you get a chance. If it looks fine you can go ahead and commit using ""git am <patch file>""."
commit 8193b5fddbff65e9e747f08ad36bc0ad41015ab0 Author: Bikas Saha <bikas@apache.org> Date:   Mon May 13 17:35:57 2013 -0700      TEZ-123. Cleanup package dependencies. (bikas) 
patch applied - thanks!
For quick reference....  autoPagingContent is the usage in question.
"I've tried patching the current SVN version of tapestry-core but the patch did not work for me either though no failure messages just silently does nothing when trying to get a page (404). This is a homebrewed version of the ""quickstart"" app.  Directory structure is  exploded/x.ear/x.war/WEB-INF/classes/... JBoss is set to deploy the exploded/ directory.  Packing the JAR in WEB-INF/lib works but JBoss/Tomcat can't do reloading or hot deployment in this case which is very annoying.  It would be nice if I could get this to work :)  Used JBoss 4.0.5"
Sorry but your testcase doesn't fail on my machine it gives me two counters in two windows - the second one with a ten second start delay.  WinXP + JDK 1.5.0_09 + Tomcat 5.5.20 + T4.0.2
"Oops - the hivemodule.xml snippet from the previous post should read:  <implementation service-id=""tapestry.multipart.ServletMultipartDecoder"">     <create-instance class=""org.apache.tapestry.multipart.MultipartDecoderImplsizeMax=-1"" model=""threaded"" /> </implementation>  Sorry for any potential confusion..."
This appears in MS-Windows environment too.  The following monkey-patch resolves the problem:   DIV.datePicker td .topLabel {      color: WindowText
T5 requires Java 1.5+ 
great idea
Great job. I'll review this patch today's night.
Thanks guys. :)  I also agree with Hyunsik's suggestion. I updated hadoop dependency to follow hadoop version of 'tajo-project'.  Check the patch again. please.  
"Thank You very much for Your positive review and for improving the patch!  Also a small correction to Your previous comment it should be:  ""unit tests included in her patch"" as You know  I'm one of the girls in this year's GSoC program.  It was a great experience to collaborate with You and I Thank You for everything!    "
+1  Jihoon Thank you for your contribution.  Sergio Thank you for your review.
+1  Looks good to me.  Thanks Hyunsik!
+1  This is a very desired feature for me. Ship it!
I'm sorry for frequently updating the issue title and contents.
Thanks for your review.  I've just committed.
Many thanks ... looks good
Thanks Lukas for pointing these issues out. Will review your fixes and do the necessary changes. The JMS transport fix should go to Axis2 Transports project.
Thanks for valuable idea.   I haven't yet decided  the API for this. Once I decide  I will publish it here . I would consider your valuable suggestion when designing API.    Thanks  Indika
Sumeet we did it purposely because if the proxy services are dynamically loaded then we need to build those services at the runtime and redeploy them which is a little bit risky on a production environment. Also there is no mechanism to check whether a particular proxy definition is updated in the registry or not because this configuration is used only at the startup.  We can add this functionality to load the proxy services only at the startup time from the registry (this doesn't mean they are dynamic) but I don't see any value there. If you could explain a bit about your exact requirement I might be able to provide an alternative to this.  Thanks Ruwan
Changes committed with revision: d3a9688d00bd520dc1c9b3a40b229aa9b10c87f0
Thank Henri and Don!  I found there are two common-validator.jar in my jboss application server env. One in %JBOSS_HOME%/server/default/lib/ and the other in the lib directory of my web application. Then I delete the latter and it works well.   Thank you so much!
Created an attachment (id=16836) struts-config 
Sorry I miss. This bug is same STR-2372. I change resolution to INVALID. 
Carl Lindberg absolutely you are right. I was not far-sighted enough to think  of that. Thank you about your point.^^ My one is not a good idea. I will try to fix it. (T.T). Thanks again. 
Created an attachment (id=3493) Patch to validator-rules.xml for bug 
If this is deemed to be a valid bug you can use my upcoming patch which simply doesn't pass the calls  to getLoginTimeout and setLoginTimeout through to the BasicDataSource.  I guess it could be a  good thing to let the BasicDataSource throw the UnsupportedOperationException notifying the  programmer that their call to the method really isn't doing anything.    OTOH they probably  care more about successfully migrating their 1.0.2 app to 1.1 and this is just getting in the way.   If they really want to know why their call to setLoginTimeout isn't working they can check the  included javadoc.  So if you decide it's a bug then there's a patch coming...
"Now the following tag:  <html:javascript dynamicJavascript=""false"" staticJavascript=""true"" />  Always adds  <script .....>  ... </script>.  I thought that staticJavascript purpose was to allow things like:  <script src=""<html:rewrite page='/staticJs.jsp' />"" type=""text/javascript""></script>  And create a jsp with something like:  <%@ page language=""java"" contentType=""text/javascript"" %> <%@ taglib uri=""struts-html"" prefix=""html"" %> <html:javascript dynamicJavascript=""false"" staticJavascript=""true"" />  And take profit of browsers cache.  No this is broken. As a workaround   <jsp:include page=""/staticJs.jsp"" flush=""true"" />  can be used but this hasn't any benefint over generating both static and dynamic javascript in the same tag (except form multiple forms per page)   If this is the intended behaviour I'm sorry for reopenning the bug.  "
Created an attachment (id=1425) Proposed patch 
Created an attachment (id=293) Trivial patch that fixes this bug 
The patch is attached.
Hi Rupert!   Sorry it took so long but i thought i'd test building in a linux environment too so i set up a Centos 6.3 machine running Maven 3.0.4 and Java 1.6_41.   Got the exact same error on both machines. I have attached corresponding logs both from windows8 and centos to this issue. Link here: https://issues.apache.org/jira/secure/attachment/12570981/surefire_reportsR1450112_win8_centos6.3.zip  Kind regards Esse  EDIT: I'll also run mvn clean install for just jenatdb with logging when i get home.
Hi Florent where is the code you extracted?
Reopened because of issues with RC5
As Olivier does all the great work here I assigned the issue to him. Thank you!
Patch attached.
Thanks Jarcec!
The patch is in: https://git-wip-us.apache.org/repos/asf?p=sqoop.git
Committed to sqoop2. Thanks Jarcec!
Thanks Jarcec - that clarifies.
Committed to trunk. Thanks Jarcec!
Patch is in.  Thanks Jarcec.
Patch committed. Thanks Jarek!
Thanks  Klaus!
I don't think this is a bug. CachedSqlEntityProcessor will execute the query only once and that is its USP. If you don't want the caching then just use SqlEntityProcessor.
Committed revision 1504570. Committed revision 1504596. Committed revision 1504597. 
"bq. accountNames => {""shalinmangar""""steffkes""""otis""'ErikHatcher'}  Shalin Stefan Otis and Erik: I've added all of you to the solr-committers solr-admins and confluence-administrators groups."
Committed revision 1480515. Committed revision 1480517. 
Thanks Uwe!
bq. Here the patch for the groovy script.  cool looks good thanks!
Fixed the bug description - sorry for the noise
I've gotten to the bottom of this - patch attached.
Hi which version do I need to apply the patch on?  
Thanks for the commit!
Thanks Martijn!
First draft.  This just does the mapping in the constructor to the comparator.  We could do setNextReader but I can't imagine it will really make much difference given the small number of items that we typically would expect to be elevated.
I created a class that extends UpdateRequestProcessor which logs calls to each method. In the console output you'll see that only the processAdd methods are called when using the DIH in debug mode and the user checks verbose and commit.  I've attached the SOLR configuration that can be used to replicate the issue. I'm assuming that once Lucene commits the files the UpdateRequestProcessor.processCommit method should be called too.   *UpdateRequestProcessorTest.class*  package org.apache.solr.handler.dataimport
Bulk close after 3.5 is released
Added to trunk in #1098800 3.x in #1098896  sorry about visad.UnimplementedException!
see also SOLR-2399 -- this has done some great work revamping the admin UI
"Hi Tommaso  bq. However I think it should be good if it was possible to alternatively get rid of the uimaConfig file defining each parameter inside the Processor with Solr elements (str/lst/int etc.) as well.  I've done this in the attached patch. Please review it. I'm not confident about the part:  {code} <lst name=""fieldMappings"">   <lst name=""mapping"">     <str name=""type"">org.apache.uima.SentenceAnnotation</str>     <str name=""feature"">coveredText</str>     <str name=""field"">sentence</str>   </lst> </lst> {code}  the structure is appropriate or not."
The DismaxRequestHandler and StandardRequestHandler are both deprecated and replaced with SearchHandler.     
bq. Actually DIH started as a standalone webapp inside AOL. We changed it because we didn't want to duplicate the schema in two places and also because we wanted to have it available by default in Solr installations.  Another web app means you need to procure hardware plan capacity/failover create firewall holes etc  Even if it were a standalone app I would still run it on the same hardware that runs Solr though I might run it on the secondary servers that aren't normally seeing query load.  Why would you need to have the schema in two places?  My DIH config doesn't mention any field names because all Solr field names match the MySQL field names.  Even if they didn't I'm not sure why it would be any different than any other SolrJ client which doesn't need to have a copy of the schema.  bq. Talking to multiple collections was never a goal for DIH ‚Äì I'm not sure what value it will bring.   I've got a sharded index
"{quote} ...but even if we don't do that i suppose it's also conceivable that someone might have their own Similarity implementation that is expensive to instantiate (ie: maintains some big in memory data structures?) and might want to be able to declare one instance and then refer to it by name in many different fieldType declarations. {quote}  I don't think this is really a use case we need to support: the purpose of Similarity today is to do term weighting not to be a huge data-structure holder.  While I know Mike's original patch went this way with LUCENE-2392 (e.g. norms) I'm not sure i like it being in Similarity in the future either.  Otherwise concepts like lazy-loading norms and all this other stuff get pushed onto the sim which is an awkward place (imagine if you have many fields).   So I think we shouldn't really design for abuses of the API. If there are other use cases for ""named similarity"" that have to do with term weighting I'm interested. "
Provide MMap and SimpleFS DirectoryFactory impls.  Didn't include the DirectIOLinuxDirectory yet since that still seems highly experimental.
Test cases for geomultidist() function.  Add this and SOLR.2155.p3.patch
branch_3x: Committed revision 1003739.
An updated documentation of the Processor is now at http://wiki.apache.org/solr/LanguageDetection  @Lance: What params were on your mind as candidates for keyword instead of true/false and for what potential future reasons?
Hi everyone   What's the status of this issue? Have you found and workarounds?
This is something that some people have asked for since my CNET days...  I thought there was already an open issue for this but I can't seem to find it (so I guess not!)
Hi Andreas  Sorry for my late reply.  I haven't looked in to the difference between using the ResponseBuilder#getFilters and using filter's in a normal query. Are there any functional differences between the two ways other than that one of them utilizes Solr's filterCache and the other doesn't?
Dumb user
Can the ExtractionRequestHandler go away?
This looks good to me as a first step - tested with both config and schema errors.  Would be nice if single core with the solr.xml also worked but no biggie - we can fix with the rest of multi-core.  bq.  Note for no good reason what so ever   Well I think it was supposed to work (even though the whole idea is kind of broken anway) cause it attempted to so reason is prob a bug ...
I can also see this would get screwed up in Zookeeper mode if the elevate file didn't exist.
Committed revision 949471.  merged to branch-1.4 for 1.4.1
Did you clean everything out?
"Of course I totally agree with Yonik.  I don't care that much what the default include is (upper lower ...) as long as it doesn't double-count. Double-counting is bad -- it can lead to a bad user experience. There's something about ""lower"" that I feel makes it slightly better than ""upper"" but I can't really explain the rationale. I don't think there's any point in compliance with legacy if nobody depended on the behavior (they couldn't specify the behavior before either).  Just because its easy to set the include doesn't mean the default is arbitrary.  Any way if the default remains to double-count I'm going to insist that my readers for the second edition of my book change this value."
We got lots of votes on this issue seems like we should take some action here! I will assign it and make sure it will be resolved rather sooner than later.  bq. Please add this feauture  to get expectations right we are working on releasing 3.2 soon and this one should not block it. I will work towards 3.3 here
Thanks Otis. 
Committed revision 771270.
I'll add resuableToken support to this patch.
Committed revision 741710.  Thanks Patrick!
fixed in trunk... thanks Henri!
bq. I'm attaching a patch which adds a second query() method to SolrServer which takes the request method as the second argument.  Shouldn't that be specific to an HTTP server?
Sorry this new patch is the correct one. Still learning the ropes :-)
Ah this is in Solr-land sorry thought it was Lucene. 
added in rev 546223.  Thanks Will!
Otis You need to grab the 'zipped' version aka solr-215.patch.zip (since June 23). I was trying to be space & bandwidth friendly... Sorry I did not make it more obvious in some previous comments. Henri
Mike: patch reads nice and clean to me (didn't try applying though)  two nits:   1) it would be good to have a test of the case where a boolean with the default boost is specified in one bq and a seperate blank bq is specified to force the first BQ to be treated as a single query  2) let's assign  params.getParams(DMP.BQ) to a temp variable so we don't have to call it twice in three lines.
Hi Guillaume  I think that what you are saying is right and i find ( despite is on the specification or not ) that to have the error status is quite useful.  But i don't agree that if InOnly MEP terminate with an ERROR status it should propagated back.  I agree totally with Gianfranco this should be done only when we're working in sync mode otherwise it's better not  to propagate the error back and use feature like restart from the failure point that we've just implemeted.  Do you agree with this??  Andrea 
maybe we can replace wsn-http-binding in the future
Guillaume Thanks for your commit. It fix this problem and my example works fine now with this fix. 
Guillaume  I took a quick look at your suggestions.  I agree that we can reduce the code a bit.  However I think that we need to keep the activate method as it initializes the servingXml internals.   I'm not sure about the deactivate method.  I also noticed that you have added a patch but being new to jira I'm not sure if that means that you've made changes to my attachment or something else.  Are you still looking for me to correct the formatting and to remove the extraneous methods/classes?  Thanks James
Thanks. Moved
That's indeed odd - I didn't knowingly reformat - must have been a mishap..
Great thanks for fixing the OSGi import. I'll create a new issue for the failing trunk build with more info... https://issues.apache.org/jira/browse/SLING-2770
Looks good. Thanks for your work on this!
Hi Ian  this looks brilliant to me! So fat +1 from me.
path of proposed change
dupe of SLING-1529
Hi [~justinedelson] thanks for applying the patch and fixing the formatting.
Closing as a duplicate of SLING-394
Looks good thanks!
Performing the conversion of the time out interval from seconds to milliseconds using longs in the getTimeout method avoids the overflow. Could still add additional methods to the Session API if desired.
Awesome - thanks so much for the submission Scott!
Sorry for my delay. I would have answered early but I completely missed the notification mail about Christiano's comment :(  @Christiano: I've just tested it again and it seams to work for me:  {code} karaf@root> list START LEVEL 100  List Threshold: 50    ID   State         Blueprint      Level  Name [  42] [Active     ] [            ] [   60] Apache Shiro :: Core (1.2.0.SNAPSHOT) [  43] [Active     ] [            ] [   60] Apache ServiceMix :: Bundles :: ehcache (2.3.0.1) [  44] [Active     ] [            ] [   60] Apache Shiro :: Support :: EHCache (1.2.0.SNAPSHOT) {code}  Looking into the shiro ehcache pom i found the following:  {code} <Import-Package>   org.apache.shiro*
Finally it should be noted that the 'noSession' filter only prevents new sessions from being created.  It allows access to any existing session that might have been created in another part of the application by the application developer.
Committed by Ryan Baxter as revision 1352277 
patch applied.  thanks! 
Code looks good to me patch's been committed thanks!  Awesome to now be able both the 0.8 and 0.9 messaging API through the same interface this is going to save us a lot of headaches :)
Looks good to me. Works for me  too. :-) 
Bruno you mentioned in a gtalk conversation that you had a patch for this but I can't find it here in JIRA.. could you attach it please? thanks!
I had no idea about fetching binary data sorry. Is it flash?   Looks like my patch addressed all three points failing only for handling raw bytes.
Created an attachment (id=16986) Proposed addition to Javadocs. 
Patches for 1) applied to trunk and J6
 Looks good to me.  Colm.
Re-attaching as I didn't grant ASF license first time I attached it!
{quote} because they are non-javadoc Eclipse-related only and not everybody uses Eclipse. {quote}  ouch... sorry about that. You will not see that again.
"No I never see the ""Completed rebuilding index"" message. Here's what I see on startup:  INFO  2011-03-21 09:50:41961 IndexManagerImpl:<init> - search enabled: true INFO  2011-03-21 09:50:41973 IndexManagerImpl:<init> - index dir: /home/raible/roller_data/search-index INFO  2011-03-21 09:50:42011 ReferrerQueueManagerImpl:<init> - Instantiating Referrer Queue Manager INFO  2011-03-21 09:50:42012 ReferrerQueueManagerImpl:<init> - Asynchronous referrer processing = false INFO  2011-03-21 09:50:42020 ThreadManagerImpl:<init> - Instantiating Thread Manager INFO  2011-03-21 09:50:42031 WebloggerFactory:bootstrap - Roller Weblogger business tier successfully bootstrapped INFO  2011-03-21 09:50:42031 WebloggerFactory:bootstrap -    Version: 5.0.0-RC4 INFO  2011-03-21 09:50:42032 WebloggerFactory:bootstrap -    Revision: r1076253 INFO  2011-03-21 09:50:42032 WebloggerImpl:initialize - Initializing Roller Weblogger business tier WARN  2011-03-21 09:50:49462 SharedThemeFromDir:loadThemeFromDisk - Couldn't read theme [Andreas08] preview image file [sm-theme-andreas08.png] INFO  2011-03-21 09:50:49482 ThemeManagerImpl:initialize - Loaded 7 themes from disk. INFO  2011-03-21 09:50:49482 ThreadManagerImpl:initialize - Initializing task: ScheduledEntriesTask INFO  2011-03-21 09:50:49944 ThreadManagerImpl:initialize - Initializing task: ResetHitCountsTask INFO  2011-03-21 09:50:49993 ThreadManagerImpl:initialize - Initializing task: TurnoverReferersTask INFO  2011-03-21 09:50:50049 ThreadManagerImpl:initialize - Initializing task: PingQueueTask DEBUG 2011-03-21 09:50:50077 IndexManagerImpl:initialize - Index inconsistent: new DEBUG 2011-03-21 09:50:50079 IndexManagerImpl:initialize - Creating index INFO  2011-03-21 09:50:50122 IndexManagerImpl:initialize - Index was inconsistent. Rebuilding index in the background... DEBUG 2011-03-21 09:50:50127 IndexManagerImpl:scheduleIndexOperation - Starting scheduled index operation: org.apache.roller.weblogger.business.search.operations.RebuildWebsiteIndexOperation DEBUG 2011-03-21 09:50:50191 WriteToIndexOperation:run - Starting search index operation DEBUG 2011-03-21 09:50:50192 RebuildWebsiteIndexOperation:doRun - Reindexining entire site INFO  2011-03-21 09:50:50275 WebloggerImpl:initialize - Roller Weblogger business tier successfully initialized INFO  2011-03-21 09:50:50276 RollerContext:initializeSecurityFeatures - Remember Me enabled: true INFO  2011-03-21 09:50:50278 RollerContext:initializeSecurityFeatures - Password Encryption Algorithm set to 'SHA' INFO  2011-03-21 09:50:50278 RollerContext:setupVelocity - Initializing Velocity INFO  2011-03-21 09:50:56132 RequestMappingFilter:init - Request mapping filter initialized 1 mappers configured. INFO  2011-03-21 09:50:56157 IPBanFilter:init - INIT IPBanFilter INFO  2011-03-21 09:50:56158 CompressionFilter:init - Compressed Output ENABLED INFO  2011-03-21 09:50:56186 MediaResourceServlet:init - Initializing ResourceServlet INFO  2011-03-21 09:50:56220 PageServlet:init - Initializing PageServlet INFO  2011-03-21 09:50:56222 WeblogPageCache:<init> - {timeout=3600 enabled=true size=400 id=cache.weblogpage} INFO  2011-03-21 09:50:56229 CacheManager:<clinit> - Cache Manager Initialized. INFO  2011-03-21 09:50:56230 CacheManager:<clinit> - Cache Factory = org.apache.roller.weblogger.util.cache.ExpiringLRUCacheFactoryImpl INFO  2011-03-21 09:50:56236 SiteWideCache:<init> - {timeout=1800 enabled=true size=50 id=cache.sitewide} INFO  2011-03-21 09:50:56237 PageServlet:init - Referrer processing enabled = true INFO  2011-03-21 09:50:56241 FeedServlet:init - Initializing FeedServlet INFO  2011-03-21 09:50:56244 WeblogFeedCache:<init> - {timeout=3600 enabled=true size=200 id=cache.weblogfeed} INFO  2011-03-21 09:50:56246 ResourceServlet:init - Initializing ResourceServlet INFO  2011-03-21 09:50:56249 SearchServlet:init - Initializing SearchServlet INFO  2011-03-21 09:50:56255 CommentServlet:init - Initializing CommentServlet INFO  2011-03-21 09:50:56297 CommentValidationManager:<init> - Configured CommentValidator: Blacklist Comment Validator / org.apache.roller.weblogger.ui.rendering.plugins.comments.BlacklistCommentValidator INFO  2011-03-21 09:50:56299 CommentValidationManager:<init> - Configured CommentValidator: Excess Links Comment Validator / org.apache.roller.weblogger.ui.rendering.plugins.comments.ExcessLinksCommentValidator INFO  2011-03-21 09:50:56301 CommentValidationManager:<init> - Configured CommentValidator: Excess Size Comment Validator / org.apache.roller.weblogger.ui.rendering.plugins.comments.ExcessSizeCommentValidator INFO  2011-03-21 09:50:56301 CommentValidationManager:<init> - Configured 3 CommentValidators INFO  2011-03-21 09:50:56302 CommentServlet:init - Comment Throttling DISABLED INFO  2011-03-21 09:50:56309 PlanetFeedServlet:init - Initializing PlanetRssServlet INFO  2011-03-21 09:50:56311 PlanetCache:<init> - Planet cache = {timeout=1800 enabled=true size=10 id=cache.planet} INFO  2011-03-21 09:50:56314 CommentValidationManager:<init> - Configured CommentValidator: Blacklist Comment Validator / org.apache.roller.weblogger.ui.rendering.plugins.comments.BlacklistCommentValidator INFO  2011-03-21 09:50:56314 CommentValidationManager:<init> - Configured CommentValidator: Excess Links Comment Validator / org.apache.roller.weblogger.ui.rendering.plugins.comments.ExcessLinksCommentValidator INFO  2011-03-21 09:50:56315 CommentValidationManager:<init> - Configured CommentValidator: Excess Size Comment Validator / org.apache.roller.weblogger.ui.rendering.plugins.comments.ExcessSizeCommentValidator INFO  2011-03-21 09:50:56315 CommentValidationManager:<init> - Configured 3 CommentValidators INFO  2011-03-21 09:50:56318 RSDServlet:init - Initializing RSDServlet INFO  2011-03-21 09:50:56320 PreviewResourceServlet:init - Initializing PreviewResourceServlet INFO  2011-03-21 09:50:56340 PreviewServlet:init - Initializing PreviewServlet INFO  2011-03-21 09:50:56342 PreviewThemeImageServlet:init - Initializing PreviewThemeImageServlet INFO  2011-03-21 09:51:24197 ContinuousWorkerThread:run - HitCountQueueProcessor Started. INFO  2011-03-21 09:50:56342 PreviewThemeImageServlet:init - Initializing PreviewThemeImageServlet INFO  2011-03-21 09:51:24197 ContinuousWorkerThread:run - HitCountQueueProcessor Started. INFO  2011-03-21 09:51:29473 Blacklist:<clinit> - Initializing MT Blacklist WARN  2011-03-21 09:51:29478 Blacklist:loadBlacklistFromFile - Couldn't find downloaded blacklist loaded blacklist.txt from classpath instead INFO  2011-03-21 09:51:29494 Blacklist:loadBlacklistFromFile - Number of blacklist string rules: 3102 INFO  2011-03-21 09:51:29495 Blacklist:loadBlacklistFromFile - Number of blacklist regex rules: 15 INFO  2011-03-21 09:51:35146 RendererManager:<clinit> - Renderer Manager Initialized. INFO  2011-03-21 09:51:35151 RollerVelocity:<clinit> - Initializing Velocity Rendering Engine DEBUG 2011-03-21 09:51:35940 IndexManagerImpl:executeIndexOperationNow - Executing index operation now: org.apache.roller.weblogger.business.search.operations.SearchOperation DEBUG 2011-03-21 09:51:36324 IndexManagerImpl:executeIndexOperationNow - Executing index operation now: org.apache.roller.weblogger.business.search.operations.SearchOperation DEBUG 2011-03-21 09:53:49889 IndexManagerImpl:executeIndexOperationNow - Executing index operation now: org.apache.roller.weblogger.business.search.operations.SearchOperation DEBUG 2011-03-21 09:53:50561 IndexManagerImpl:executeIndexOperationNow - Executing index operation now: org.apache.roller.weblogger.business.search.operations.SearchOperation"
Thanks for the patch!  http://svn.apache.org/viewvc?view=revision&revision=1361531
Closing as a duplicate of ROL-1642.
A patch file is attached here to address these problems. Many files have been touched. Sorry for it. But I'm sure there are more files than these that have i18n problems. I'd like to dig more into it as soon as these critical ones are resolved.
I must have clicked the wrong link.  I didn't mean to mark this resolved.
This was a temporary connectivity issue.  You can close this bug.  Thank you.
newPost now sets publishEntry to true.
Applied the patch. Thanks Dennis!
Patch applied in revision 1055819.  
Applied the patch : At revision: 1051526
Lets fix this post rampart-1.3
Released in Qpid 0.24 http://qpid.apache.org/releases/qpid-0.24/index.html
Reviewed by Rob.  Approve for 0.20.
Changes look reasonable to me.
Hi Robbie would you mind reviewing this commit?
Thanks for catching this I have fixed it.
This change was only applied to the 0.5.x-dev branch. It needs to be merged to trunk.
Looks good to me.
This is a duplicate of QPID-2488
Hi Aidan can you review this change please thanks.
Updating 'Fix For'  to Unknown on issues not targeted for 0.8
Hi Aidan can you take care of this when you do QPID-1010. Thanks
Hey Aidan can you cast your eye over this again. Thanks.
the code has been checked in. Thanks to Gordon for that. 
All existing documentation/discussion from Moin Moin wiki now copied across to Confluence JIRA and re-formatted as appropriate.  Should now all be updating on Confluence wiki and retire Moin Moin in a couple of weeks when people have been able to check that their pages look ok on Confluence.
Hi Rustam Finally I will not commit the IMAP-351 patch so it will be good that you attach your patch here. Thx Eric
Fixed in 1.4 release branch in r605105.   Leaving open until fix (with other pending changes) is ported back to trunk.
sorry should be: path -p6 < pluto-1.1.0-taglib-el.diff
missed encoding for non-array request parameters.  It doesn't look like I can remove previously attached files.  Whoever is reviewing the code  should use the latest patch.
Wow fast. Thanks!
Committed to trunk. Thank you Lorand!
committed to trunk. Thanks [~elserj]!
[~bikassaha] Thanks for the heads-up Bikas! This JIRA is not concerned with the Tez integration for Pig and is simply the abstraction in Pig to allow for alternate ExecutionEngines in Pig. But will certainly change this on the Tez integration side of stuff.  Thanks a lot [~cheolsoo] for continuing this! I think everything looks good from my end. I can certainly see why we may want to keep this on a different branch until everything is finalized. Certain things may still need more work. For example OutputStats is not completed abstracted out as it still has references to POStore which is a MR implementation construct. ScriptState/PPNL/JobStats may still need more abstraction (especially PPNL) and reworking to incorporate a new ExecutionEngine abstraction. I think what we have done here is the minimum foundation for an abstraction though and it would be appropriate to put into trunk but these are not my decisions to make.   With regard to public methods that were changed I don't think most of them are a big deal besides as Cheolsoo said the PigServer throwing PigException. I never thought IOException was a good exception to throw but I think reverting PigServer back to IOException as it is userfacing code is not a big deal. The rest of the method signature changes shouldn't be worrisome because most of them are internal to the project.   However the change from JobStats to MRJobStats while necessary (as each ExecutionEngine would have it's own type of JobStats it would present to the end user) could be problematic because it is userfacing code and would probably break people who were previously using JobStats. That I think is the most important thing to keep in mind. The task of making the PPNL and JobStats clearly tied to the ExecutionEngine should be thought through also.
Committed to trunk. Thanks Mathias!
Thanks for volunteering for this Prashanth!
Committed to 0.11.1 branch and trunk. Thanks a ton Kai!
Committed to trunk. Thanks Johnny!
Sorry I missed Bill's comment.  bq. We've seen similar exceptions when loading data that contains text with the column delimiter in it which produces shorter than expected tuples. Could that be the case here?  I don't think that's the case here.  However I've made many silly mistakes&misunderstandings in pig before.  Let me double check.
Patch committed to trunk and 0.11 branch.  Zhijie thanks for the patch!
Thanks Jon. +1. Patch looks good.   Minor nitpick I have is that it would be nice to give the test a more relevant name than testAutomaticallyMadeName. Something like testRelationAliasForBinCond. But I am not going to insist. 
Committed to trunk. Thanks for the review Alan!
"changing the name of JIRA from ""multithreaded"" to ""parallel"" as we've done it with forks instead of threads."
Yes I missed this basic case. Thanks for pointing out. I will cancel this patch.
Committed to trunk. Thanks Jeff!
Hi Alan I was merely commenting on the title of the JIRA not the UDF name.
Yes actually I take out the hbase part when I commit.
+1.  Looks good to me.
Review board comment: https://reviews.apache.org/r/314/
Attached patch should apply cleanly to the current trunk. Please review.
Patch committed to trunk. Thanks Niraj.
bq. Though pig itself compiled fine and is ready to go the contrib projects (owlzebrapiggybank/hiverc) didnt compile I think because either it didn't download dependices of those projects or didn't include them in the build path.  Ashutosh yes. I did realize it and as you rightly guessed it is because the ivy-dependency list doesn't have some jars that are actually being used by contrib packages. This is not an issue related to eclipse-classpath. However there has to be a JIRA opened to solve this issue of downloading the missing jars by ivy.   Can you please file a JIRA for this? Thanks
"Hi Gianmarco Thanks for your concern. Actually we need one additional step to make bin/pig work. We shall copy $PIG_HOME/build/pig-0.8.0-dev.jar to $PIG_HOME/pig-0.8.0-core.jar. This will be handled in ant's ""package"" target when releasing. But if you check out from svn we will do this additional step to work with bin/pig."
Patch is committed to the trunk. Thanks Niraj.
Just back from vacation. Have updated the code with required changes. It should be good to go now. Pradeep can you or any other committer review it ?  
Patch was commited on May 13 2009.
Hudson does not work well patch has been manually tested.
Patch looks good. One minor comment PlanHelper.LoadStoreFinder may better be PlanHelper.LoadStoreNativeFinder.
patch committed. Thanks pradeep!
Thanks Pi.  I do not think there is any special tricks besides those with Linux (such as you will need ant junit java svn etc).  If you want you can also send me your pig.jar and then I will try it out for you.  Best regards Xu   org.apache.pig.impl.logicalLayer.parser.QueryParser.Expr(QueryParser.java:373>> )  
Fix checked in at revision 648768.  Thanks Xu.
In MapReducePlanCompiler.java   {code} if (PigContext.instantiateFuncFromSpec(materializedResult.outFileSpec.getFuncSpec())          instanceof ReversibleLoadStoreFunc) {     POMapreduce pom = new POMapreduce(logicalKey.getScope()                                       nodeIdGenerator.getNextNodeId(logicalKey.getScope())                                       execEngine.getPhysicalOpTable()                                       logicalKey                                       pigContext)
Antonio could you just create a patch file that I can apply.
Totally agree. I don't see any good reason why Pig should require 1.6 at this stage. Don't make it harder for the users (and developers under OSX - that includes me) than it already is.
>Tilman Hausherr   hello finally it  works! I just downloaded the revision 1535956 and bulded it with Ant. and added the new *.jar to my project's build path. it printed very well.  thank you very much.
"I've revised DateConverter to conform to java 6:      changed isAlphabetic to isDigit (and reversed the ?: values)      use SimpleDateFormat(""Z"") as Tilman suggested.  Also fixed some Javadoc in both DateConverter and TestDateUtil"
change default assembly behaviour in preflight
Hello Andreas  Thank you for the information.  Shall try the same and upload the patch shortly.  Thanks & Regards Ravikiran Mane.  
I'm afraid one can't extract the text from the given pdfs. Both are using fonts with a non human readable encoding and as there isn't included any mapping you'll get rubbish instead of the text. Even the acrobat reader can't extract the text.
A PDF which demonstrates the problem
Hi  Here is the missing file. I'm sorry for the delay.  Regards Eric
After applying Mathias patch the sample documents works fine.  Thanks Mathias.
Direct link to mail item didn't work.
Will be taken care of next releases 
released with OWB-1.1.4
"Ok I just downloaded trunk and the patch is 99% the same with mine so I'll close the issue now...One comment though and sorry for nitpicking...Shouldn't the second constructor simply be ""this(patterns null)"
"If you run the train command you get an error in the model serializer I suggest to train on the ppa data set serialize the model and then load it again to ensure there are no runtime errors in this code path. Its also easier to debug in an IDE if it fails in a junit test.  That is the exception I get:  Caused by: java.lang.NullPointerException 
Committed revision 1475954.
"Hi Eduardo  I have tried with your settings for the timezone. I was not able to reproduce it. The meeting was correctly displayed in the calendar the meeting times in the iCal invitations where send fine I tried also with ""simple email"". The invitation hash also worked fine and had the correct time validity."
"Sorry Alvaro  lot of things need to be done at the same time.  But I am still not 100% clear what you want me to do / change.  I put installation/wiki links on top-right now: http://incubator.apache.org/openmeetings/index.html  What about the links to the Tutorials you want to put those in the section ""Installation and Upgrade"" right?  Sebastian"
Johannes --   Thanks for the complete testcase! Sorry about taking so long to fix this one.   Thanks Rick
Hi Michael thank you for your answer. I thought that it would not be so easy to solve this issue. Unfortunately.  I agree with you that the main problem here is that a copy action is missing and I guess AttachStrategy.persist is the right place to add some kind of copy functionality.  I started looking into the source code of the enhanced class from the test. PersistenceCapable declares a public method to copy fields (pcCopyFields(...)). Unfortunately you can't use in AttachStrategy.persist because the entity to persist has no statemanager at this point (an exception InvalidStateException will be the result).  My suggestion is to modify the class enhancement and remove the StateManager check in pcCopyFields (I don't see the need for this check).  Afterwards you can use pcCopyFields in AttachStrategy.persist by adding something like      ...         if (manager.getCopyNew()) {             int[] fields = new int[meta.getFields().length]
Thanks for the patch Janko. I put the changes into 1.3.x and 2.0.0. 
"Added the following to getRollbackOnly():  if (status == Status.STATUS_NO_TRANSACTION) {     throw new IllegalStateException(""There is no transaction in progess."")"
committed to branch-4.0 and trunk. Thanks Rohini.
Closing issue
Didn't modify any testcases because its just some minor typo fixes.  
Thanks Robert. Committed to trunk.
Closing issue
I had almost the same interface for the command-line option in mind but sticking to the previous formats for specifying the id:  ./wmgr-client --url http://localhost:9001 --operation --getWorkflowInstMet --id <workflowInstId>  And in return display the values in the format as you suggested above.  
Hi Antonio  I can take this one if nobody is working on it.  Would be a nice one to get my feet wet... :)  Thx Sam
Hi Suresh  I think this task is also related to AMBER-63 since both OAuth 2 and Open Id Connect use JSON Web Token (JWT).  
Thanks Jacques :)
Sorry I put a comment here which was for another issue (tired as said already)
Hi Tri  Those files looks good. I cursorily checked only.CommonUiLabels.xml.patch but from their sides I guess the others are good as well. But done from the OFBiz roo directory it's the main OFBiz directory where you fine the LICENSE and APACHE2_HEADER files. Anyway not a big deal I will try to apply them as is and will let you know  You don't have to remove the old files as you can see they are now grayed and it's good that you checked the grant license box.  Thanks
https://cwiki.apache.org/confluence/display/OFBADMIN/OFBiz+Contributors+Best+Practices#OFBizContributorsBestPractices-HowtoSendinYourContributions%28orhowtocreateandapplypatches%29
Fixed rev 1190423. Thanks Jose! 
Sorry again I tried with the same revision same language same theme and I use also FF4 and I still don't reproduce (see screenshot-1)  It would be interesting ot have other persons tests
Hi Leon thanks i'll take a look. Anyway i thought of refactoring this parsing mechanism we can do better :-).   Cheers Sascha
Thank you Jacques for the quick commite !!  Pierre 
Thanks Ren√©  Your patch is in trunk at r1061167 R10.04 at r1061173 R9.04 at r1061174   
Thanks Ankit  Your patch is in trunk at r1060220 I did not backport as it's not breaking anything
Thanks Erwan for you're effort :-)
Hi Sascha  There is an overlap with OFBIZ-3843 could you please check?  Thanks
Hi Erwan  If you don't mind I have re-assigned to you as you assigned yourself the umbrella task
Done at 946323 and 946322 Thanks Blas !
Done at revs 946320 and 946321   thanks Blas
Hi Jacques hi Ankit ... i think i found the reason why we can't call layer recursivly ... i made a patch but i can't sync my trunk today (i'm at our friends house and they have only internet via gps connection ... it's so slow :-D). I will provide the patch on monday morning.  Have a good Weekend Sascha
Thanks Amit & Vivek - Committed at r907620.  -- Ashish
Thanks Mirdul committed in trunk r903428 and 9.04 r903429
Thank you Ashish Vijaywargiya and Pranay Pandey :)   Thanks and Regards -- Akash Jain
Great last enhancements thanks guys!
Ashish This is working fine for me. Please take a look at https://issues.apache.org/jira/browse/OFBIZ-2277
"Hi Bilgin  you are right the entitymode.xml can be removed but I when I add it I'm thinking to add a new filed to PosTerminalInternTx  entity to store ""Pos Paid Reason"" instead of store it in the reasonComment field.  I have already created some enumeration into DemoPosData.xml but it is still not been used. There are still a lot of things that has been not implemented or not working so contribution from other people are welcome. Removing the hardcoded value pos-1 into WebPosEvents.java at line 77 is something still to be done. I'm thinking to add a combo box after logged in to choose the posTerminalId but I didn't get the time to do it.  Thanks  Marco"
Thanks Bruno and Bilgin  You patches are in trunk revision: 691953   Great to see good cooperation at work :) 
Jacopo  Thank you for your work! I'll test it today and let you know what I find.
Sorry to hack your issue Bilgin my intention is to keep readable traces (in ML you can't read easily stack)
Thanks Alok Agnihotri for your valuable patch. Special thanks to Rishi SolankiPranay PandeyBrajesh Patel and others in helping Alok.  Changes are in rev # 607341.  -- Ashish Vijaywargiya
Sorry Jacques I have not seen that it was a grouped bugs.  In this case I have used to set in the grouped bugs the sum of the components used by detailed issues.  I didn't like unknow components.  Otherwise we can add a new fictitious component - GROUPED ISSUES - and assign this component to this type of issue.   Thanks  Marco  
Yes I have been watching OFBIZ-1453 with interest.  I approve of the issue and implementation and didn't have anything to add so I haven't been involved.  The thing I have been thinking about is that there's some assumptions to be made here for pricing and the type of question.  I.e. multiselect questions should display the absolute price.  I'm also trying to work over some other scenarios.  I'll clean up what I have an submit a patch tomorrow. 
Marco BTW I have only helped Santosh Malviya for OFBIZ-1468 where ever he needs and reviewed his work. After that Its only his effort to convert java to minilang + testing the patch. So majority of credit goes to Santosh Malviya :)
"I have added          <property file=""framework/base/config/cache.properties""/>         <echo message=""NOTICE: deleting ${cache.file.store}.db""/>         <delete file=""${cache.file.store}.db"" verbose=""true""/>  to the clean task of my local main build.xml.  After some more testing/discussion perhaps I will post it as a patch. "
This patch solved this issue in a test case.
About EPL licenceplease have a look at http://people.apache.org/~rubys/3party.html#category-b. Seems fine with some light constraints
"Can't remember how to put the state of this issue to ""In progress"" not a big deal anyway..."
Ray Jacoo  I finally commited it in revision: 485087.  Thanks 
Thanks Scott  I have committed your last work in svn with rev. 7876 
Works fine with my minimal test case and the tutorial. Thank you!
Hi Daisy  could you please dispatch this review to one of your team? Mingfei did not respond on that and I would like to be certain we got all provided patches with us for 0.7.  Thanks in advance Svante
Applied. Thanks!
Sorry for the late reply. Your corrections look good I've just applied them. Thanks!
The patch looks good just applied on the 1.1 branch and trunk. Thanks a lot keep them coming! :)
Could you make sure that the following path exists on your machine:  C:\Program Files\Apache\Tomcat 6.0\webapps\ode\WEB-INF/jpadb  It sometimes happen that Tomcat for some reason fails to open the WAR which results in an incomplete deployment.
i don't think that any special filtering should be performed for the access control content such as e.g. rep:policy nodes. but as far as i can see you didn't incorporate this into the patch right?  testing for Tree#exists in the NodeDelegate looks ok to me...
that's nice! The patch looks good Emanuele :)
Further optimized caching in KernelNodeStore a bit in revision: 1450145  The test now just runs for a very long time (with -Xmx128m) and didn't run out of memory so far on my machine. Though it is still working on 51200 child nodes after it reported '25600 nodes in 1440293 ms'.
In revision 1406185 I applied the patch from https://github.com/jukka/jackrabbit-oak/commit/e01558418008e41a94c44ea00494f6a939ed58a2. This fixes the problem.
[~anchela] which improvements do you have in mind?
Hi Talat - no this patch is for the branch_2x branch only.
Committed @revision 1440266 in trunk Thanks Lufeng if and when you get around to the patch for 2.x I can review. The patches for tests are very welcome in Nutch. Thank you. 
Looks good to me Markus. +1
+1 thanks
+1 thanks. Don't forget to add line to CHANGES.txt when committing
Actually i made a simple test on 2 small linkdb and i didn't see any improvment. You're right. There is no need to add it.
"Using nutch with solr has been a very demanding request so it will be very useful when this makes into trunk. I have spend some time reviewing the patch which I find quite elegant.   Some improvements to the patch would be  - make NutchDocument implement VersionedWritable instead of writable and delegate version checking to superclass - refactor getDetails() methods in HitDetailer to Searcher (it is not likely that a class would implement Searcher but not HitDetailer) - use Searcher delete HitDetailer and SearchBean  - Rename XXXBean classes so that they do not include ""bean"". (I think it is confusing to have bean objects that have non-trivial functionality) - refactor LuceneSearchBean.VERSION to RPCSearchBean - remove unrelated changes from the patch.(the changes in NGramProfile HTMLLanguageParserLanguageIdentifier... correct me if i'm wrong)  As far as i can see we do not need any metadata for Solr backend and only need StoreIndex and Vector options for lucene backend so i think we can simplify NutchDocument#metadata. We may implement :   {code} class FieldMeta { o.a.l.document.Field.Store store"
Release Candidate 1 of this patch.  This patch contains: + add IP Address to CrawlDatum Version 5 (as byte[4])  + a IpAddress Resolver (map runnable) tool to lookup the IP's multithreaded + add a property to define if the IpAddress Resolver should be started as a part of the crawlDb update tool to update the parseoutput folder (contains CrawlDatum Status Linked) of a segment before updating the crawlDb. + using cached IP during Generation  Please review this patch and give me any improvement suggestion I think this is a very important issue since it helps to do _real_ whole web crawls and not end up in a honey pot after some fetch iterations. Also if you like please vote for this issue. :-) Thanks.
Patch applied to trunk/ . Thank you!
 Hi Luca  I've applied the changes you mentioned and it worked fine on my end (Windows).  Can you try this on your end as well? I've attached the patch.  Thanks!
Re: setReaderThread I didn't know we had such a method.  It looks like it was added here: http://cvs.apache.org/viewcvs.cgi/jakarta-commons/net/src/java/org/apache/commons/net/telnet/TelnetClient.java?rev=1.9&view=markup  Other than adding documentation to FTPClient about this it sounds like like there isn't any other action to take on this report??? 
Yes it can be resolved. Thank You!
"Unfortunately we can't do that because that is not explicit on the spec javadoc and there is a way to do what is expected using ""targets"" property."
The patches look good :)
thanks to Jakob Korherr for this patch
I didn't know about a Trinidad regex Validator. I've created it from scratch.  Didn't look for any Validator code on the internet because I wanted to make sure it was JSF 2.0 compliant.
Duplicate of MYFACES-2970
Sorry I was not able to create one diff-file so I added for every build.xml an own diff.
HI Ronald  The fix I put in on the 30th caused pages to stop drawing in the RC1.  I have reverted part of the fix for this bug to get 657 resolved. Could you please take a look at the comments for 657 and test out the head of the 1.1.1 branch to make sure that this version works for your case.
Mathias please close this issue as it is not reproducing any more...  Thanks.
Sorry I use JDK 1.4.2_06 and not 1.4.1 :)
Fixed. Thanks for report (even if I'm not sure empty password is a good idea :-) ). 
"sure only ""/"" works. if path="""" that's considered as no path defined."
I can confirm this is not happening on Ubuntu 12.04 with OpenJDK 1.6.0_24. Did anyone get a chance to look at this apparently Mac-specific issue?
"Bertrand - nice work. This is a great idea and the patch looks good overall. Couple of points:  - Don't forget the Apache header on the new Errors class - Maybe do the grammar corrections on the counter error messages separately? Just so we keep the commits to a single issue each.  - I'm not sure we need to retain the delegating ""formatValueList"" method in TestDriver. Something to discuss...   As for using Guava to do the string join - I know MRUnit used to have it as a dependency but this was removed in MRUNIT-50. Probably not worth bringing it back for such a simple method. "
Thanks that looks good now
Hi.  The code above is a copy of the CharsetUtil class just run within a Junit Test case.  There is no exception other than junit.framework.AssertionFailedError.  Are you able to reproduce the error?  Thanks  Richard
Hi I've started working on this. I think I have an idea of what to do design-wise but if anyone has any suggestions please let me know. 
Fixed in subversion repository as of r1328492
Phil  I must have missed this email. I am sorry. I will get this done and the other changes to support the UpdatingMultipleLinearRegression class.  I updated my source and noticed the changes were missing. I did my detective work and noticed this.  Mea Culpa!!  -Greg   
{quote} I don't think it makes sense to argue about who the exception messages are for [...] {quote}  I think the opposite because it has an impact on the library design. Not that CM cannot go on with the current way
This seems good to me. +1 to apply it
3.1.0-incubating released!
Hi Chris  Thanks for your detailed response.  Thanks
I've committed this to trunk branch-2 and branch-2.2.  Yingda thank you for the patch.  Chuan thank you for help with the code review.
#NAME?
Thanks Karthik!  I committed this to trunk branch-2 and branch-2.1-beta.
Thanks for taking a look Bikas and Devaraj. Committing this.
Thanks.  I'll look into this.
+1 looks good  Thanks Mayank
Attached another refresh
+1 looks good. Checking this in.
[~arpitgupta] thanks for helping narrow this down!
Attaching updated patches. Arun let me know it this looks good.  Thanks
Thanks Harsh good to know.
Thanks Sandy. Committed to trunk and branch-2.
Could you please share how is it impacting ?
[~acmurthy] did you commit to both branch-1.2 and branch-1?
Looks good.  Minor nit can you change info.wait(0)
Committed to branch-2 and trunk. Thanks Ahmed!
Incorporating Konstantin's comment  Thanks Mayank
I just thought of one more thing we should do.  We should make the StringInterner as @Public and @Stable.  The API is simple enough I don't see much of a problem locking it down.
Thanks for the patch Daryn  +1  I put it into trunk branch-2 and branch-0.23
Hi Jason! I was thinking one of those parameters was the time the NM should wait before sending the SIGTERM. Alas I was wrong ContainerLaunch.java:337 sends the SIGTERM pretty much instantly. That is messing me up in MAPREDUCE-4135.  I'm still thinking having a small time delay before sending even the SIGTERM should be good. If we can do it on the NM and not on the RM I think we might be able to conserve RM resources. 
Sorry looks like we took to long to get to this the patch no longer applies.  Can you please upmerge to latest?
Can you please address the findbugs warning. (inconsistent synchronization)  I did a quick look at your patch and I am a bit confused by the implementation of setSignaled.  I realize that you did not really change the code at all but is there a reason that the parameter is ignored?  If you don't know I can look into it myself.
Sorry to come in late. Some clarifications: # MR1 JT kills all running tasks on a TT when it's deemed 'lost'. # It also kills all completed maps on that TT for 'active' jobs. # The tasks are marked KILLED rather than FAILED and thus don't count towards the job which is correct since it wasn't the job's fault.  Hope this helps.
I just committed this to trunk and branch-2.0. Thanks Xeiguiming!
+1 The patch looks good to me. I will commit this later.
I just committed this. Thanks Vinod!
I just committed this to trunk and branch-0.23. Thanks Arun!
+1 looks good to me.
Actually now that I think of it we never had anything exposed via jmx for the RM? Looks like this is the first bean we are adding. Is that right? I thought some of the work that Thomas did on web services was also exposed via jmx. No? 
Attaching a patch that adds API for accessing the other info (which is not writtent to trace file).
+1. Just committed this to trunk and branch-0.23. Thanks Jason!
Nit-corrected patch. Committing.
I just committed this. Thanks Anupam!
+1 looks good to me. Trying it out.
Thanks for the explanation +1 for the patch.
Uploaded new patch by addressing review comments from Amar.
I just committed this to both trunk and MR-279. Thanks Jeffrey!
addressed review comments.  Thanks Vinod.
+1  looks good
+1 lgtm to get rid of the extra logging and to kill the child process.
Committed to trunk and branch-22. Thanks Ari!
+1 patch looks good
I just committed this. Thanks Patrick!
+1 The patch looks good to me.
addressed the Cos and Balaji comments. Latest patch for yahoo security branch. 
I just committed this. Thank you Scott and Priyo.
Patch looks good to me also.  bq. -1 core tests. TestSpecialCharactersInOutputPath failed with NoClassDefFoundError. I ran the same test on my machine with the patch. It ran successfully.
Thanks for the update Tom this is getting close!  Some more comments:  {quote} > src/java/org/apache/hadoop/mapreduce/TaskType.java > -> Public? Stable? It is public. Not sure about whether it is stable yet. {quote} I'd tend to lean towards making it Stable to ensure it's never broken it probably deserves that status given how central it is to the framework. Thoughts? I don't see either 'audience' for this yet it the patch maybe you missed it?  bq. Are MarkableIterator and MarkableIteratorInterface public user classes? The unit test for them (TestValueIterReset) implies that the user instantiates a MarkableIterator. +1 public  bq. I left all of the lib.db classes public evolving since they are used by various extensions and users. Does this sound reasonable? +1  {quote} > src/java/org/apache/hadoop/mapreduce/Job.java > -> public  Yes.  > src/java/org/apache/hadoop/mapreduce/JobCounter.java > -> public  Yes.  > src/java/org/apache/hadoop/mapreduce/JobPriority.java > -> public  Yes. {quote}  Again I don't see 'audience' as 'public' another human miss on your part? Or am I seeing the wrong patch?  ----  Comments on rest of the classes I missed in the first pass:  src/java/org/apache/hadoop/mapreduce/security/token/package-info.java -> Unstable src/java/org/apache/hadoop/mapreduce/security/token/delegation/package-info.java -> Unstable src/java/org/apache/hadoop/mapreduce/TaskTrackerInfo.java -> Public used in Cluster src/java/org/apache/hadoop/mapreduce/util/package-info.java -> Unstable src/java/org/apache/hadoop/mapreduce/TaskCompletionEvent.java -> Public Job.getTaskCompletionEvent src/java/org/apache/hadoop/mapred/JobInProgress.java -> limited-private for schedulers src/java/org/apache/hadoop/mapred/Task.java -> limited-private for schedulers src/java/org/apache/hadoop/mapred/JobEndNotifier.java -> public maybe evolving since end-users use this directly src/java/org/apache/hadoop/mapred/LineRecordReader.java -> limited-private (mr pig) src/java/org/apache/hadoop/mapred/JobProfile.java -> Odd I thought this was 'public' - but I can't find any uses for it. The FairScheduler uses it so 'limited-private' ? src/java/org/apache/hadoop/mapred/TaskCompletionEvent.java -> public accessible via JobClient 
uploading the patch for commit to internal branch it has review comments from sreekanth and cos implemented. 
Looks like your change did not fix the findbugs. But i think you need to suppress the findbugs warning : HRS_REQUEST_PARAMETER_TO_HTTP_HEADER. It is suppressed for jobdetails.jsp in MAPREDUCE-1185.
Patch that fixes this problem and adds a test case demonstrating it.
Ported to trunk
I just committed this. Thanks Jitendra!
The patch looks good now and the tests are all running fine now. +1.  Let's wait for Hudson..
+1. Looks good to me.
I've just committed this. Thanks Aaron!
+1  I committed this. Thanks Kay Kay!
I just committed this to trunk thanks Owen
+1  I committed this. Thanks Hong!
+1 patch looks good.
"Patch looks mostly good to me.  One comment: I think the name ""moveAndDeleteLocalFiles"" isn't quite descriptive enough. Perhaps ""asyncDeletePathOnEachVolume"" or something? The fact that the path is relative to *all* volumes and will be deleted on each of them is the key part I didn't understand at the first pass through the JIRA.  I agree with Vinod that it would be nice to share code with CleanupQueue but would be fine seeing it in another JIRA."
+1  I committed this. Thanks Jothi!
I just committed this. Thanks Boris!
thanks tom....let me see if I can come up with a test case for the LineReader reset. I did forget adding a test case for that.  I probably file that as part of this patch. 
Updating patch synch'ed with trunk.
I just committed this. Thanks Omer!
Thanks for taking this patch looks good. Is this good to be committed?
yes go ahead.   
Never mind figured it out will be committing patch in the next few days.
"(If it's just reading ints I was thinking just write 4-byte ints. That's got to be the fastest of all.)  The author would be Ted really his call. If it's more of an example for the book it could be attached to the book. If it stays that's cool too just need to have a think about fixing/documenting the issues raised here.  You've raised a different an interesting point about performance though. You find that the slow-down is actually in addToVector where it converts a String to byte[]? The thing is the corresponding line in the ""fast"" version skips this step and adds null.  Indeed also passing null in the ""normal"" version makes it twice as fast for me. It's still twice as slow as the ""fast"" version though. But I do wonder whether the example deserves a bit more attention. I may not know what I'm doing. Is that a difference that shouldn't exist between the two benchmarks?"
OK understood. Can you re-create the patch? It's out of sync with head at the moment. 
I see what you mean
Just some variations
"{quote} This wasn't a problem with my patch right?  That was an issue of the mahout script in trunk itself? {quote}  Yes it was a problem with the script in trunk. I believe this was due to the fact that the job files were on the classpath instead of all of the dependency jars. Adding the job files to the classpath does not add the dependency jars they contain to the classpath as well. So no you didn't add this but it should be fixed (and is in the patch)  {quote} What is the -core option for?  I've never used it how does it work? {quote}  when you're running bin/mahout in the context of a build the -core option is used to tell it to use the build classpath instead of the classpath used for a binary release. This just follows the pattern established (by Doug?) in the hadoop and nutch launch scripts.  {quote} Also added a help message for the 'run' argument. {quote}  near line 72 in bin/mahout: (this is different from the --help question I had)  {code}   echo ""  seq2sparse            generate sparse vectors from a sequence file""   echo ""  vectordump            dump vectors from a sequence file""   echo ""  run                   run mahout tasks using the MahoutDriver see: http://cwiki.apache.org/MAHOUT/mahoutdriver.html"" {code}  {quote} So you already added the ability to load via classpath right? If we merge that way of thinking with what I'm currently working on (having a configurable ""MAHOUT_CONF_DIR"" which is used for all these props files) we could just have the mahout shell script just add MAHOUT_CONF_DIR to the classpath (the way you already have it adding the hardwired core/src/main/resources directory) and then it would work that way. {quote}  Yep that should do it as long as MAHOUT_CONF_DIR appears before src/main/resources we should be good to go. It should be added outside of the section of the script that determines if -core has been specified on the command-line.  "
The inline patch came out garbled. Same patch attached.
It could have been created as a patch and that is far as its gotten.   Assuming that we're talking we're just talking about creating a simple .snk to create strongly named assemblies when talking about signing assembly:  I didn't see a .snk file in the Lucene.Net_2_9_4g branch when setting up the build scripts. I haven't looked in trunk yet.    The Lucene.Net_4e branch should have a already have a snk. I could add the same snk file to trunk and the 2.9.4 branch when I go add the build scripts to the trunk this weekend so that all the branches are building strong assemblies.  Someone would still need to go back to the tag and create a 2.9.2 version using the snk whenever the next release does come out.    
Hi Bianco First of all could you add a apache licence to the file VectorHighlightMapper.cs?  Your work is very good and pass all tests but it is not like just a simple bug fix and there is a divergence from FVH java. This makes life hard while making new versions' ports.  All Lucene.Net community! Any idea about what  we should do?  DIGY  
Hi Nick  Can you please re-create this patch as I can't get the code to compile?  For starters I can't get the class AttributeImplItem to compile.  Please use the latest trunk when doing so  Thanks.  -- George
Hi DIGY  I like to know a bit more about this patch:  1) what test case is it fixing? 2) how did you determine the race condition?  The changes to the ThreadClass is considerable and I'm trying to understand why this wasn't a problem in earlier versions.  Thanks.  -- George 
I rather we don't work on older versions.  If this is still an issue in 2.3.1 please submit a new patch for 2.3.1.  Thanks.
"Patch looks great!  Thanks Artem.  No more mixing in of fuzzy-ness into AnalyzingSuggester.  It looks like we are doing the utf8 conversion + det twice per lookup once in convertAutomaton and once in getFullPrefixPaths.  But I think this is inevitable: the first conversion is on the ""straight"" automaton for exactFirst match and the second one is on the lev automaton for non-exactFirst.  Really we should only do the first convertAutomaton if exactFirst is true ... but this is an optimization so we don't need to fix it now. "
Committed to trunk and 4x. Thanks Simon!
Thanks for raising these documentation issues! I just committed a fix.
Following the recent facets work I think that as part of this issue we should do the following two things (in addition to what I described above):  * Make OrdinalPolicy an enum with two constants (ALL/NO_PARENTS). It's already hard to support just these two (see LUCENE-4610 and LUCENE-4600) and it's not at all clear how to support arbitrary OrdinalPoilcy-ies that users will provide. ** Rather if one really wishes to encode only say levels 3 and below he can extend FacetFields and provide his own CategoryListBuilder. ** For the search side he'll need to provide whatever will work for him (I cannot even describe here what API exactly because of the complexity)  * Nuke PathPolicy. One can extend FacetFields and provide his own DrillDownStream. I'll need to check about that one but it looks like we can get rid of it too.
"I just glanced through in general: this is similar to the hack patch i used exploring LUCENE-4089 though I just used a Map<StringString>.  The part i didnt like when exploring was more related to how term index/term dictionary are separated: {quote} divisor: generalize this into something simple like a Map<StringString> of codec ""parameters"" that you set on IWC/IR. split divisor from ""don't load terms index"". define these as constants where they belong. I got unhappy here in the ""splitting"" part because I wanted the divisor part in TermsIndexReaderBase but that doesnt extend FieldsProducer (where i wanted the ""don't load"" part) and wrap the terms dict instead its backwards and terms dict wraps the TermsIndexReaderBase... maybe we should fix that too? I think this confusing the way it is but I didnt look at how difficult this would be. {quote}  But I think maybe I was trying to tackle too much at once... still as an ""untyped"" parameter I thought it would be useful to fix the semantics all in one break rather than causing confusion down the road. "
I commented out the assertion for this test ... it's not valid.
Thanks Scott. git formatted patches are fine in my opinion: lets get this fixed
Patch adds maybeRefreshBlocking which blocks on refreshLock. It also:  * Renames reopenLock to refreshLock * Shares the refresh logic between maybeRefresh and maybeRefreshBlocking. * Switches to use ReentrantLock instead of Semaphore(1): ** It allows to protectively obtain the lock in doMaybeRefresh (see comment in the code) ** It is better in general because it's equivalent to Semaphore(1) yet protects against an accidental bug where someone changes Semaphore(1) to Semaphore(>1).  I'll add a CHANGES entry after the patch is reviewed and we agree on the approach.
Committed.  Thanks Chris!
"lemme see if I can help with the test. I feel bad I didn't supply one with the prototype patch.  About the Solr integration: this looks good! We can use a similar approach for autosuggest too so this could configure the analyzer for LUCENE-3842.  I wonder if we should allow separate configuration of ""index"" and ""query"" analyzers? I know I came up with some use-cases for that for autosuggest but I'm not sure about spellchecking. I guess it wouldn't be overkill to allow it though."
Thanks Dawid!
"bq. I assumed modules doesn't need to be self-contained like Lucene or Solr. I can fix that by enforcing tools' compilation in that macro... I'll do that. bq. Steve will you double check again if everything works  Yes everything works for me now thanks!  bq. and commit this in?  Is there some reason why you can't do this?  IMO committers should commit their own work.  bq. I didn't put an entry into CHANGES so you'd have to add it if it qualifies at all to be mentioned there.  IMO this definitely warrants a CHANGES.txt entry.  This should also be backported to branch_3x.  bq. This reminds me of the ""infrastructure tools"" problem we had in Carrot2. We finally decided to simply have them as a stand-alone project living within the same repository space with a stored versioned binary artefact updated when tools had to be updated (rarely). This does version a binary file but you don't need to worry about recompiling things over and over.  +1 to do this for this and any other Lucene/Solr Ant tasks."
"Thanks Dawid.  bq. Yes this is pretty much the top-n nodes reordering that I did albeit without any optimization of how many n to take (the hardcoded magic constants should probably be justified somehow? Or replaced by a default in FST somewhere?).  bq. Deciding how many nodes to reorder is I think hard ‚Äì I failed to provide any sensible fast heuristic for that and I simply do a simulated annealing to find a local optimum.  Yeah the algo is simplistic now... and it does force caller to pick the params (though minInCountDeref=3 and maxDerefNodes=Inf are probably pretty good)... we can and should make it more sophisticated over time.  We have at least one spare bit to still use in the arc flags :)  bq. One thing I was wondering is why you decided to integrate the packer with the fst ‚Äì wouldn't it be cleaner to separate packing from construction? Granted this requires a double pass over the fst nodes and more intermediate memory but it wouldn't add any more complexity to the builder which is already ehm a bit complex . You can compare this design in Morfologik:  Well... it's tricky.  First I decided to change node targets to ords so that pack could use an array to (relatively!) efficiently hold node data eg inCount newAddress etc.  That required making the first pass FST ""modal"" (deref'd or not).  If we didn't do this then the packer would have to use even less RAM efficient data structures (eg Map<IntX>) I think?  Second the format written by the packer is tightly coupled with the FST reading ie there are sizable differences when reading packed vs unpacked FST.  But I agree it'd be cleaner if we could move packing out (eg Util.pack) and more strongly decouple packing from FST format...  One thing I'd really like to somehow do is create different classes for FST writing vs reading and different classes for each format.  We now have write-ord write-non-ord read-packed read-unpacked (and even the two readers have 3 different modes depending on INPUT_TYPE).  "
From the dev list didn't want to lose this background (or make Uwe type it again <G>)  The idea was to maybe replace RAMDirectory by a ‚Äúclone‚Äø of MMapDirectory that uses large DirectByteBuffers outside the JVM heap. The current RAMDirectory is very limited (buffersize hardcoded to 8 KB if you have a 50 Gigabyte Index in this RAMDirectory your GC simply drives crazy ‚Äì we investigated this several times for customers. RAMDirectory was in fact several times slower than a simple disk-based MMapDir). Also the locking on the RAMFile class is horrible as for large indexes you have to change buffer several times when seeking/reading/‚Ä¶ which does heavily locking. In contrast MMapDir is completely lock-free!   Until there is no replacement we will not remove it but the current RAMDirectory is not useable for large indexes. That‚Äôs a limitation and the design of this class does not support anything else. It‚Äôs currently unfixable and instead of putting work into fixing it the time should be spent in working on a new ByteBuffer-based RAMDir with larger blocs/blocs that merge or IOContext helping to calculate the file size before writing it (e.g. when triggering a merge you know the approximate size of the file before so you can allocate a buffer that‚Äôs better than 8 Kilobytes). Also directByteBuffer helps to make GC happy as the RAMdir is outside JVM heap.....  RAMdir uses more time for switching buffers than reading the data. The problem is that MMapDir does not support *writing* and that why we plan to improve this. Have you tried MMapDir for read access in comparison to RAMDirectory for a larger index it outperforms several times (depending on OS and if file data is in FS cache already). The new directory will simply mimic the MMapIndexInput add MMapIndexOutput but not based on a mmapped buffer instead a in-memory (Direct)ByteBuffer (outside or inside JVM heap ‚Äì both will be supported). This simplifies code a lot.   The discussions about the limitations of crappy RAMDirectory were discussed on conferences sorry. We did *not*decide to remove it (without a patch/replacement). The whole ‚Äúmessage‚Äø on the issue was that RAMDirectory is a bad idea. The recommended approach at the moment to handle large in-ram directories would be to use a tmpfs on Linux/Solaris and use MMapDir on top (for larger indexes). The MMap would then directly map the RAM of the underlying tmpfs..... 
Committed trunk revision: 1206033 Now backporting.
bq. Opened LUCENE-3595.  thanks! I committed this to trunk and backported to 3.x   nice iterations.. 
I think its a good idea to go ahead and put a patch together so we can discuss it directly.
bq. Can we just make it final when we backport this change?   Duh no we can't since we have core IR impls subclassing IR...
Fixed.  3.x didn't have any problems
I don't think there is any sense in this who cares?  We reported this crash to Oracle in plenty of time and the *worse* wrong-results bug has been open since May 13: http://bugs.sun.com/bugdatabase/view_bug.do?bug_id=7044738 but Oracle decided not to fix that too. 
"I think what happens is all bugs are initially internal to Oracle and they need to be ""opened up"" to the public. I presume this is so that critical bug reports don't immediately become available for exploits... but I'm just guessing."
Committed revision 1165174.
attached a fix
Committed revision 1128830 to trunk. I will now backport to 3x.
Previous patch was wrong. Here a new one.
"bq. Hmmm infoStream is just for debugging... should we really make it volatile?  I'll remove its volatile...  {quote} bq. IWC cannot be made immutable ‚Äì you build it up incrementally (new IWC(...).setThis(...).setThat(...)). Its fields cannot be final.  Setters can return modified immutable copy of 'this'. So you get both incremental building and immutability. {quote}  Oh yeah.  But then we'd clone the full IWC on every set... this seems like overkill in the name of ""purity"".  {quote} What about earlier compromise mentioned by Shay Mark me? Keep setters for 'live' properties on IW. This clearly draws the line and you don't have to consult Javadocs for each and every setting to know if you can change it live or not. {quote}  I really don't like that this approach would split IW configuration into two places.  Like you look at the javadocs for IWC and think that you cannot change the RAM buffer size.  IWC should be the one place you go to see which settings you can change about the IW.  That some of these settings take effect ""live"" while others do not is really an orthogonal (and I think secondary ie handled fine w/ jdocs) aspect/concern. "
Uwe: I don't interpret it that way!  I don't think our indexinputs should be doing writes!
Committed optimization in trunk revision: 1037077 
bq. I'm gonna hold off on LUCENE-2771 until we figure this one out... because it would make your getSequentialSubReaders in the synced=true case quite heavy (without modifications).  Sorry I was wrong on this... I totally forgot the norms cache is lazy-loaded always in that patch. I'll commit LUCENE-2771 it shouldnt affect this!
+1 patch looks good. 
Ported back to 3.x  Committed revision 991537.
"{quote} I don't really know much about NamedSPILoader but I think what you're suggesting. How would we support Factories loading unrelated classes like they can through ResourceLoader now? Assume they're on the classpath and use Class.forName? {quote}  It needs more discussion (and input from Uwe would help!) but it works like Charset.forName(""ASCII"") etc. We use this already for codecs and postingsformats (Codec.forName Codec.listAllCodecs ...).  Have a look at lucene/core/src/resources/META-INF/services for the idea. Basically you ""register"" your classes in your jar file this way: additional jar files (e.g. look at lucene/test-framework/src/resources/META-INF) can load more classes.  So this could support some idea like TokenizerFactory.forName(""Whitespace"") or something simple like that. So someone would not need to use org.apache.solr.analysis.xxx namespace to be able to load their analyzer stuff easily they use whatever package they want and register in their META_INF. And added jar files (other analysis jars) are automatically available this way.  I think Uwe mentioned this idea before though I think he had Analyzers in mind (e.g. provide language code and get back analyzer or something). Anyway thats for another issue :)  Just something worth consideration if we want to make these modules really pluggable. On the other hand we shouldn't use anything overkill if its not the right fit... "
Static? Weren't you against that!?   But if we remove back compat from analyzers why do we need Version? Or is this API bw that we remove?
Committed revision 941607.
Good catch!  Thanks for the thorough explanation and suggestions.  I think it all makes sense.  Will work on a patch.
Yes I'm continuing along the path Chris started with his first patch mine is coming soon.  Nikola
There is a bug in PayloadNearQuery. If there are multiple top level spans that match the query only the payloads of the first one are retrieved. This patch fixes this bug by iterating over all the top level spans to get the payloads (see 'setFreqCurrentDoc')  > The base explain method can't be abstract. Something like Ah right. This is included in the patch  >The changes don't seem thread safe any more since there are now member variables. It may still be all right but have you looked at this aspect?  I guess that could be said about PayloadTermSpanScorer and PayloadNearSpanScorer too (payloadScore payloadsSeen). As for the PayloadFunction classes they seem lightweight enough to be created with each query. Is there a better pattern?  Peter   
Looks like a good solution!  Thanks for taking care of this Uwe!  {quote} Should we backport this to 2.9 and 3.0 (which is easy)? {quote}  +1
bq. If you back-port this to 2.9 you can't use any of the java.util.concurrent.* Very good point! - didn't thought about back porting at all.   bq. I'm not sure you need a separate SearcherHolder class - can't you re-use IndexReader's decRef/incRef? I guess I did not see the simplicity the reader offers - blind due to  java.util.concurrent.* :)  bq. I think there are some thread safety issues..  this is weird - on my dev machine and in the patch it is not synchronized.. on the machine I run the tests it is. Anyway you are right.   I changed the code to be compatible with 2.9 using indexReaders.dec/incRef.. will attache in a minute   
fixed to use reader.termDocs(null) for delete check. 
Looks good.  bq. I didn't add Version to StopFilter nor StopAnalyzer
+      if (!more) { +        return false
Simon thanks please commit this :) 
Commited in r823180 thx robert
Thanks Steve!
{quote} Adriano: Can you summarize all your changes in both issues into a changes.txt entry for both branches? {quote}  Hi Uwe yes I can do it I will need to review the entire code again (3x and trunk). I plan to do this during the weekend. But if you want commit Vinicius's code and I commit the changes to changes.txt later 
We still haven't coded in the items on the comments above (Jul 1 and 2). I hope to get to it some time soon though but if you'd like to give those a shot go ahead.
Attached patch.  I plan to commit in a day or two.
I'm looking through DateTools now and can't help but want to clean it up some.  One thing I see that is odd is the use of a Calendar in timeToString(longresolution).  The first two lines look like this right now: {code} calInstance.setTimeInMillis(round(time resolution))
Jason  did you get a chanse to try this out? It seems to work fine for me and I plan to pop it in the trunk in a few days. I think I'll have to add a warning of some kind in runtime though as it could slow down the index a bit if the reader is way fragmented.
bq. I did hit the error while I did that but I will verify again.  Ugh.  If that's the case then maybe catch the OOM in the read and fallback to the temp buffer read solution?
Strange things going on. With Google Chrome uploading patch files corrupts the file. With MSIE it worked. Sorry for the noise. Yesterday it worked normally...
Committed revision 728746.  Thanks Shai!
Are there any plans to release a 2.4.1? If yes can this fix be included?
Uwe can't you use ExtendedFieldCache.getLongs passing in your own LongParser?
"bq. you tweaked a couple little things with the standard cache capture state  Actually I think I just moved things around?  EG I made it the StandardTermsDictReader's job to seek the termsIn file I moved docCount ""up"" and I made a single cache entry.  I think I also removed a few attrs that we didn't need to store... and downgraded skipOffset from long -> int (it's int on trunk)."
Committed revision 698035.  it's just about having an optional ant property for specifying the full path to svnversion ... i've made the Hudson config changes for Lucene-trunk (add -Dsvnversion.exe=/opt/subversion-current/bin/svnversion) and manually kicked off build#594.  If i missed something re-open and i'll take a look
Just curious how did you solve the split packages issues and invalid symbolic names with some Lucene modules? I can't see it in the parent pom.
bq. Here's a patch for the general case and it also adds a warning that you should set your similarity with Similarity.setDefault especially if you omit norms.   Is there no way to remove this stupid static default and deprecate Similarity.(g|s)etDefault()? Can we not use the Similarity from IndexWriter for the case of NormsWriter?
Adds docid Field to the index for EnwikiDocMaker
Brings this patch back up to trunk level.
Thanks patch applied. 
Are there any plans to also publish the new release to the Maven 1 repository on ibiblio.org? We at Jackrabbit still use Maven 1.0.2 as our build tool.
I just remembered one of the reasons why i didn't do this the last time i looked at it: i don't think FunctionQuery has any good unit tests in the Solr code base -- there might be some tests that use the SOlrTestHarness to trigger function queries but they aren't really portable.
Thanks I've committed your patch leaving out the change to equals() and not  removing mergeBooleanQueries() as that is a public method which someone might  be using. Also could you please check if the test case is correct now? I  couldn't apply that part of your patch cleanly and something might have been  broken.   
Here is a Test case to reproduce it. I launch it on a JDK1.6 and it deadlocks each 6 to 10 run.
"Created an attachment (id=17581) Patch for build.xml to add index=""true"" for jar tasks "
just pending announcement now
I did nothing special. My understanding was that simply trying to test under JDeveloper caused the problem. Your report says removing xmlparserv2 causes JDeveloper not to start.  Is there something else I need to do to cause the problem?  FYI - I created a Maven project with the code above as the only application. I then imported the application which was a bit frustrating as it didn't seem to accomplish much. I then had to manually add the log4j 2 jars into the classpath along with target/classes and had to make a couple of other changes so that it knew how things were laid out in the project. I then ran the application from JDeveloper and it ran fine.
Thanks! :-)
Could you see my 2nd patch? :)  Thank you.
Created an attachment (id=7421) patch to o.a.c.l.SystemUtils.java. Modified declaration order. 
We can't upgrade to maven-assembly-plugin 2.3 as it breaks the build on MacOS due to https://jira.codehaus.org/browse/MASSEMBLY-588.
FWIW I didn't experience the problem with Karaf commands when using Fuse ESB (based on Karaf 2.2.5) but I did have problems with Aries Blueprint when I tried to instantiate some of our own beans as an OSGi service.  Workaround for me was to remove the Aries Proxy 0.3 bundle shipped with Fuse ESB and install Aries Proxy 0.3.1. After I did that and restarted the container the problem was resolved for me.
Red color isn't really important it was just a suggestion to be more homogeneous ... but that can be revisited in a different jira. I agree an option is a good idea for automatically acknowledging hosts.  Not sure what the default should be: the current behavior is obviously to not confirm so we could keep that one or go for a safer one I don't have any strong opinion on that.
Thanks for fixing it!
"Working: - Bash on Linux  Not Working: - Bash on Solaris - CSH on Solaris - KSH on AIX - Bash on AIX  So you're right. I close this bug as ""work as designed"".  Sorry for the noise :)"
thanks for the patch Michael Van Geertruy :)
Thanks for the reviews guys!
Thanks for the patch. Committed to 0.8.
Quick fix to interchange the order of constructor arguments of ClientIdAndTopic.
Sorry for the late review. Have a few minor questions/comments.  60. What happens if have 2 instances of Consumers with the same clientid in the same jvm? Does one of them fail because it fails to register metrics? Ditto for Producers.  61. ConsumerTopicStats: What if a topic is named AllTopics? We use to handle this by adding a - in topic specific stats.  62. ZookeeperConsumerConnector: Do we need to validate groupid?  63. ClientId: Does the clientid length need to be different from topic length?  64. AbstractFetcherThread: When building a fetch request do we need to pass in brokerInfo as part of the client id? BrokerInfo contains the source broker info and the fetch requests are always made to the source broker.  
Thanks for getting started on this. I have a couple of requests -  1. Could you please upload a patch to this JIRA and grant it to Apache ?  2. This patch doesn't apply cleanly to trunk would you mind updating a patch that would ?   It will make it much easier for us to review it.   Also when you said the zk connect option hangs did you get a chance to take a look at the debug/trace logs to see where it hangs ? Do you mind uploading those log files here ?
Hi ShengTao you would think if you follow:  1. Check if the service is there add if it is not. 2. Then add a bindingTemplate.  Then you would not be overwriting a bindingTemplates. You are right though if you are saving a service it will overwrite the existing one and it will remove any bindingTemplates if they are there. The current behavior is how the UDDI v3 spec tells us to so it but we could add a config option to differentiate from the spec.  Please let me know if you are following the above strategy and *still* seeing issues.   --Kurt  
Dupe of JUDDI-310.
Fixed eventhough these are commented out.
bundles have been promoted to OSSRH some minutes ago. It will take roughly 2-4 hours before they appear on Central so this one is close to be fixed.
"I can access the patch deletion from ""Manage attachments"" right next to the attachment list.  If you can't access it let me know which patches need to be deleted..."
Thanks very much for your response.   I want to thank your team for the great job they've done building a superior open-source solution. Not only do I use but I also promote it everywhere I go. I just did a hands-on lab using JSPWiki to create 'qwiki' WEB apps for 40 people at DEVCON 2007. It got excellent reviews.  I promote this as an Enterprise Open-source solution. If a company wanted to purchase a support contract or services for a production implementation of the product who should they contact?  Thanks again  Jim Mason   https://issues.apache.org/jira/browse/JSPWIKI-24?page=com.atlassian.jira.plugin.system.issuetabpanels:all-tabpanel ---------------------------------------------------------------------------------------------------------------   __________________________________________________ Do You Yahoo!? Tired of spam?  Yahoo! Mail has the best spam protection around  http://mail.yahoo.com  
"Looks like this problem is bigger than I thought.  I can't even get a simple form without dot-stuffing to work.  Parsing this simple script:  require [""fileinto"" ""reject"" ""tag"" ""flag""]"
It worked fine in Jetspeed 2.2.0 too
Here is a stronger/generalized version of this patch. Due to a lack to time on my part this has not been compiled or tested (sorry). Please test if you can David/Joachim.
"Added missing 2 *  package.html.  Some files need to be removed (svn del): src/java/org/apache/commons/jexl/Arithmetic.java src/java/org/apache/commons/jexl/parser/JEXLNode.java (*) src/java/org/apache/commons/jexl/util/PropertyExecutor.java src/java/org/apache/commons/jexl/util/BooleanPropertyExecutor.java src/java/org/apache/commons/jexl/util/introspection/UberspectLoggable.java src/java/org/apache/commons/jexl/util/GetExecutor.java  If on windows you really need to remove it before applying the patch otherwise it will just keep using JEXLNode.java for a class named JexlNode...  The patch does not apply cleanly especially UberspectImpl & Introspector. The ""best"" approach I've found yet is to force apply updates even if patch thinks it may have already been applied. Then for each of them copy/paste the '.rej' content replacing the end of the original file with the content at the proper place"
Great (it turned out simpler than what I would have thought). Thanks Andy.
[~mbo] yes & yes IMHO.
Re: patch looks fine. I'd include <optional> too on geronimo/ant deps as per project.xml
The fknames patch looks good!
Committed in revision 1363218.
Ok I'll add these.
"1. My feeling is that ""if (file.lastModified() < now + ACCESS_TIME_RESOLUTION)"" is not necessary since the lastModified value will already be truncated to the system resolution but I do not think it is harmful.  2. I chose to throw exception only if file.canWrite because I was trying to minimise the impact of the change. It's not clear to me whether setLastModified might work when !file.canWrite. However it certainly must work (because of GC) if file.canWrite. I would consider moving the canWrite test outside of the setLastModified call similar to getRecordIfStored it just wasn't necessary to fix the immediate problem.  3. Well not swallowed exactly but caught and converted to failure return code (-1) e.g. see BLOBInDataStore.getSize. In any case the javadoc for Property.getLength/getLengths documents -1 as a possible ""failure"" return code so it had to be tested. I think if Property.getLength/getLengths throws an exception that is already correctly handled.  Thanks for the quick response.  "
fixed. Committed revision 797662.
sorry for the delay
Stefan  > the said method is not public since it returns *all* workspace names regardless of user rights. please note that > the a session must only see/know about workspaces it is actually allowed to access.   I'm working on a garbage collector for the data store. The GC doesn't care about user rights or putting it another way it must be able to access all workspaces. Ideally I'd like to use a SystemSession but you can't get one outside RepositoryImpl or o.a.j.c package (i.e. getSystemSession(String) is package private WorkspaceInfo is protected). I understand that these APIs shouldn't be public but they're useful from within the core. In my case for the GC. I'm very interested in using another way to walk every workspace but this other way should guarantee that the repository won't shutdown during a walk operation. I'll check the solution Thomas said he'll be proposing but in the mean time that is what I'm using. Still I don't see why this APIs aren't public. Regards
Hi  We are using Jackrabbit to store/retrieve the content in my application.  Please find the attached config files of my application.    Best Regards RK OCS L3 Support +91 44 39853531 +91 98408 51525.  
Please re-open if necessary.
Hi  I just made some more (long running) tests and found some problems in the patch I submitted. The mechanism is working but it shrinks the caches too quickly and it prints too much log output (log.info instead of log.debug). I will fix those problems and submit a new patch. Sorry.  Thomas
"> I've reading the specification and can't find any reference to transient session in Node.lock(). Do you mean that Node.lock() don't modify transient session because it performs a Node.save() internally (there is no need to call save)?  whether an implementation internally calls save() is an implementation detail. ""there's no need to call save"" means that there are no transient modifications which need to be saved by the client.  > My english is a little bad an sometimes perhaps I don't use the correct words and can't express my ideas in the rigth way.  no problem most committers and a lot of people on the list are non-native english speaking  "
well the above ascii art did not really work in jira :-( will attach a file.  
Martin wrote: > Well first of all sorry if I offended someon putting the issue because it seems that I got hard responses.  You don't have to be sorry. I'm not against building a DB PM that uses a connection pool. I just had (and still have) doubts how this contributes to increased concurrency because concurrency is mostly controlled outside of the PM.  It wasn't my intention to criticise anyone on a personal level.
Oh sorry will submit them tomorrow. Hmm svn diff is really strange. Don't know why the files were not included though I did the diff from the src/java/o/a/c/jci dir.
Fixed in SVN.  Will let Vincenzo close it if he is satisfied.
Please submit an diff against the v2.3.1 branch.
Thanks for your patch and your investigations! I reopen the issue will apply the patch soon.
Tnx for the quick fix. Works perfect!
Patch applied thank you.
"I did NOT want to add a ""framework"" but rather *exactly* the opposite. "
Hi Chris could you add my username as initial developers for the Spark JIRA? Thanks.
[INFO] Repository Target 'org.apache.tez' is created. [INFO] Staging Profile 'org.apache.tez' is created. [INFO] Privileges (CRU) 'org.apache.tez - Public Repositories' are created. [INFO] Privileges (CRUD) 'org.apache.tez - Snapshots' are created. [INFO] Role 'org.apache.tez Deployment Role' is created. [INFO] Role 'tez' is added to user 'acmurthy'. [INFO] Role 'tez' is added to user 'billgraham'. [INFO] Role 'tez' is added to user 'bikas'. [INFO] Role 'tez' is added to user 'bobby'. [INFO] Role 'tez' is added to user 'cdouglas'. [INFO] Role 'tez' is added to user 'daryn'. [INFO] Role 'tez' is added to user 'ddas'. [INFO] Role 'tez' is added to user 'gates'. [INFO] Role 'tez' is added to user 'gopalv'. [INFO] Role 'tez' is added to user 'gunther'. [INFO] Role 'tez' is added to user 'hitesh'. [INFO] Role 'tez' is added to user 'hashutosh'. [INFO] Role 'tez' is added to user 'jghoman'. [INFO] Role 'tez' is added to user 'jitendra'. [INFO] Role 'tez' is added to user 'jlowe'. [INFO] Role 'tez' is added to user 'julien'. [INFO] Role 'tez' is added to user 'kevinwilfong'. [INFO] Role 'tez' is added to user 'mattmann'. [INFO] Role 'tez' is added to user 'mliddell'. [INFO] Role 'tez' is added to user 'namit'. [INFO] Role 'tez' is added to user 'nroberts'. [INFO] Role 'tez' is added to user 'omalley'. [INFO] Role 'tez' is added to user 'sseth'. [INFO] Role 'tez' is added to user 'tgraves'. [INFO] Role 'tez' is added to user 'tomwhite'. [INFO] Role 'tez' is added to user 'vikram'. [INFO] Role 'tez' is added to user 'vinodkv'. -- Nexus repository was prepared successfully. --  Configuration has been prepared now you can: * Deploy snapshot artifacts into repository https://repository.apache.org/content/repositories/snapshots * Deploy release artifacts into the staging repository https://repository.apache.org/service/local/staging/deploy/maven2 * Promote staged artifacts into repository 'Releases' * Download snapshot and release artifacts from group https://repository.apache.org/content/groups/public * Download snapshot release and staged artifacts from staging group https://repository.apache.org/content/groups/staging 
<danielsh> yes we're aware of the recurrence 
Much obliged! Thank you! :)
Hi Pieter  it looks fine now 
<pctony> Herbert sorry we cannot do this.  The scope of the blemlist AIUI is at the SVN repo level - and we run a single repo for all the ASF projects.  However buildbot works at the per-project level. Short of perhaps re-writing all of our buildbot mechanisms from the SVN master this is not do-able. Sorry. 
Thanks Joe!
Can put the info in this file on people: -rwx------  1 dblevins  dblevins  0 Jul 12 21:00 /home/dblevins/INFRA-5044 
<pctony> This has been done.  It should work just fine I'll be doing some more work on JIRA later and will force a re-index then so this might look better after that. Have a look around. 
Duplicate of INFRA-4886
Two more IDs for initial access: greid and brock.
Thanks Daniel. We will get back on this as soon as we have the correct information. Thank you. 
Thanks did that. Hopefully it syncs now. Cheers --Kurt
Sorry forgot that dev lists were merged before JMeter was made TLP
Added to all-developers group which has this permission.
dist dirs created also. 
You are missing my point sorry   By 'check in normally' I mean just commit them using 'svn add ...' 'svn commit ..' not 'svn import' you cant do that.  people.apache.org was down for a while but is now back that however is not related as you dont need to access people.apache.org to commit to svn. 
Created the DTACLOUD wiki space.
Hey thanks for that I gave it some testing and thought about it over the weekend and it looks perfect thanks!  - Aidan
Thanks!
This was taken care of already.
commits@mina created.
I've upped the httpd timeout from 5 mins to 30. I didn't see any OutOfMemoryErrors in the logs so hopefully this will fix it. Please give it another try.
Oh well. Many thanks anyways  Oleg
Thanks!
Great idea.
Hi Arpana    
I believe this is a duplicate of HTTPCORE-328  Oleg
Oleg  A minor comment.. I don't see why the close() method would throw an IOException..  thanks asankha
Olaf  Please also consider submitting a test case for this issue. This will increase the chances of the patch getting committed sooner rather then later  Oleg
Sorry I was wrong about needing to fix Gump - that just needs the build.xml patch to remove the copy of the files in lib.
You are right. I missed that point. I am +1  Oleg
That fixes my testcase.  Thank you!
Oleg  I agree it does seem that the presence of the Proxy-Authorization header on the already authenticated connection causes re-authentication.  So for NTLM to work the proxy-auth header must be removed once authenticated.  I don't think either patch 2 or 3 handles this case unless (in the case of patch 2) the host also uses NTLM.  What we really need is a way to remove NTLM headers after the authentication has succeeded.  Mike
Looks fine to me.   Oleg
Looks good to me.  Mike
Created an attachment (id=6644) SSL Guide (take 1) 
Committed to trunk. Thanks Sergey!
Committed to trunk. Thanks Prasanth!
Thank you for the patch Xuefu! I have committed it to trunk!
Committed to trunk. Thanks Teddy!
Committed to trunk. Thanks Sushanth!
Committed to trunk. Thanks Sushanth!